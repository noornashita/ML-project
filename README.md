# ML-project : Speech Recognition System using Machine Learning

## 📌 Overview
This project implements a **Speaker Recognition System** using **Machine Learning**.  
The system identifies speakers from audio samples by extracting **Mel-Frequency Cepstral Coefficients (MFCCs)** and training a classifier.  

The current baseline uses **Logistic Regression**, achieving ~50% accuracy. Future extensions include deep learning models for improved performance.

---

## Features
- 🎧 Audio preprocessing with **Librosa**
- 📊 Feature extraction using **MFCCs**
- 🤖 Speaker classification with **Scikit-learn**
- 📈 Model evaluation (Accuracy, Precision, Recall, F1-score)
- 🔧 Modular and extensible codebase (easy to plug in deep learning models)
- 📂 Works with WAV audio datasets

---

## Tech Stack
- **Python 3.x**
- [Librosa](https://librosa.org) – Audio feature extraction  
- [Scikit-learn](https://scikit-learn.org) – Machine learning models  
- [NumPy](https://numpy.org), [Pandas](https://pandas.pydata.org) – Data handling  
- [Matplotlib](https://matplotlib.org), [Seaborn](https://seaborn.pydata.org) – Visualization  
- [Jupyter Notebook](https://jupyter.org) / Google Colab – Experimentation


👨‍💻 Authors --
  Khondker Sayif Ali (ID: 2111323642)
  Md. Injamam ul Haque (ID: 2111598642)
  Nashita Tasneem Noor (ID: 2132126642)
